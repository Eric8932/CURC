

PREDICT_PROMPT1 = {
"NLI": 
"""判断下面的前提和假设之间的关系。""",

"SENTIMENT_2": 
"""判断下面的文本中蕴含的情感倾向。""",

'smp2020-ewect':
"""判断下面的文本中蕴含的情绪。""",

"ASAP_ASPECT":
"""判断下面的评论对于给定评价对象的情感倾向。""",

"bdci2018":
"""判断下面的汽车评论对于给定评价维度的情感倾向。""",

'nlpcc-stance':
"""判断下面的微博文本对于给定评论对象的立场。""",

'ReCO':
"""阅读下面的背景和问题，从选项中选择出最合适的观点。""",

"DuReader_yseorno":
"""阅读下面的问题和回答，判断回答所表述的是非观点极性。""",

"lcqmc":
"""判断下面的问题1和问题2之间的语义关系。""",

"afqmc":
"""判断下面的文本1和文本2之间的语义关系。""",

"paws":
"""判断下面的文本1和文本2之间的语义关系。""",

"bustm":
"""判断下面的问题1和问题2之间的语义关系。""",

'qbqtc':
"""判断下面的查询1和查询2之间的语义相关性。""",


"cluewsc2020":
"""判断下面的文本中##内的代词（只需要关注##内的代词）是否指代给定的名词。""",

'tnews':
"""判断下面的新闻所属的类别。""",

'domain_cls':
"""判断下面的文本所属的国民经济领域。""",

'csl':
"""判断下面的论文标题所对应的论文所属的学科门类。""",

'crisis':
"""判断下面的博文中含有的应急响应或应急救援的信息为有用、无用还是不能判断。""",


'cluener':
"""识别下面的文本中具有特定意义的实体，并将它们分类为预先定义的类别，包括：地址，书名，公司，游戏，政府，电影，姓名，组织机构，景点，职位。""",

'msra_ner':
"""识别下面的文本中具有特定意义的实体，并将它们分类为预先定义的类别，包括：地点，人物，组织。""",

'weibo_ner':
"""识别下面的文本中具有特定意义的实体，并将它们分类为预先定义的类别，包括：地点，人物，组织，地缘政治。""",


'c3':
"""阅读下面的背景和问题，从选项中选择出最合适的答案。""",

'logiqa':
"""阅读下面的背景和问题，从选项中选择出最符合问题要求的答案。""",

'logiqa2':
"""阅读下面的背景和问题，从选项中选择出最符合问题要求的答案。""",

'ekar':
"""阅读下面的问题和选项，从选项中选择出和问题中蕴含的类比关系最为一致的答案。""",

'morality':
"""判断下面的文本中蕴含的道德为正面还是负面。""",


'cold':
"""判断下面的文本针对给定的主题是否含有歧视或者冒犯的含义。""",



'MRC':
"""阅读下面的问题和段落，从段落中抽取出最合适的答案。""",

'DuReader_checklist':
"""阅读下面的问题和段落，判断段落中是否存在合适的答案。""",

'Chinese-Metaphor-Analysis':
"""判断下面的文本中用到的隐喻修辞手法。""",

"FCGEC":
"""判断下面的文本中的语法错误。""",

"NaCGEC":
"""判断下面的文本中的语法错误。"""

    }


PREDICT_PROMPT2  = {
"SENTIMENT_2": 
"""直接输出积极或者消极作为答案。""",

"ASAP_ASPECT":
"""直接输出积极、消极或者中性作为答案。""",
"bdci2018":
"""直接输出积极、消极或者中性作为答案。""",

'smp2020-ewect':
"""直接输出：积极，愤怒，悲伤，恐惧，惊奇，无情感中的一个作为答案。""",

'nlpcc-stance':
"""直接输出中立、支持或者反对作为答案。""",

'ReCO':
"""直接输出A B C其中一个作为答案。""",

"DuReader_yseorno":
"""直接输出肯定、否定或者无法确定作为答案。""",

"NLI": 
"""直接输出蕴含、矛盾或者中立作为答案。""",

"afqmc": 
"""直接输出匹配或者不匹配作为答案。""",

"lcqmc":
"""直接输出匹配或者不匹配作为答案。""",

"bustm":
"""直接输出匹配或者不匹配作为答案。""",

'qbqtc':
"""直接输出：相关程度差、有一定相关性、非常相关中的一个。 """,

"paws": 
"""直接输出匹配或者不匹配作为答案。""",


'MRC':
"""直接输出段落中连续的字符序列作为答案。""",

'DuReader_checklist':
"""如果段落中不存在问题的答案，直接输出无答案作为答案；如果段落中存在问题合适的答案，直接输出段落中连续的字符序列作为答案。""",



"c3":
"""直接输出A B C D其中一个作为答案。""",

"logiqa":
"""直接输出A B C D其中一个作为答案。""",

"logiqa2":
"""直接输出A B C D其中一个作为答案。""",





"ekar":
"""直接输出A B C D其中一个作为答案。""",

'morality':
"""直接输出正面或者负面作为答案。""",

'cold':
"""直接输出是或者否作为答案。""",

"cluewsc2020":
"""直接输出是或者否作为答案。""",

"crisis":
"""直接输出有用、无用或者不能判断作为答案。""",

"tnews":
"""直接输出：故事，文化，娱乐，体育，财经，家居，汽车，教育，科技，军事，旅行，世界，股票，农业，游戏中的一个。""",

'domain_cls':
"""直接输出：交通运输仓储邮政，住宿餐饮，信息软件，农业，制造业，卫生医疗，国际组织，建筑，房地产，政府组织，教育，文体娱乐，水利环境，电力燃气水生产，科学技术，租赁法律，采矿，金融中的一个。""",

'csl':
"""直接输出：法学，工学，经济学，理学，农学，管理学，医学，历史学，艺术学，哲学，教育学，军事学，文学中的一个。""",



'Chinese-Metaphor-Analysis':
"""直接输出没有隐喻，动词隐喻，名词隐喻中的一个作为答案。""",

"FCGEC":
"""直接输出语序不当，搭配不当，成分缺失，成分赘余，结构混乱，不合逻辑，语意不明，无错误中的一个作为答案。""",

"NaCGEC":
"""直接输出搭配不当，不合逻辑，语序不当，成分残缺，成分赘余，句式杂糅，无错误中的一个作为答案。""",

'cluener':
"""直接输出格式为：实体-类别；实体-类别；实体-类别的实体及其类别作为答案。每个实体及对应类别输出一次即可。如果文本中没有实体存在，输出无实体。""",

'msra_ner':
"""直接输出格式为：实体-类别；实体-类别；实体-类别的实体及其类别作为答案。每个实体及对应类别输出一次即可。如果文本中没有实体存在，输出无实体。""",
'weibo_ner':
"""直接输出格式为：实体-类别；实体-类别；实体-类别的实体及其类别作为答案。每个实体及对应类别输出一次即可。如果文本中没有实体存在，输出无实体。""",

}